---
title: "Assignment 5"
author: "Paula Suarez"
date: "29/10/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

**Assignment 5**  

*Description of the Dataset:*  
The data contained in the file `mydata.csv` has 205 observations and 7 variables and is a modified version of the `melanoma` dataset found in the `boot` package. The data consist of measurements made on patients with malignant melanoma. Each patient had their tumour removed by surgery at the Department of Plastic Surgery, University Hospital of Odense, Denmark during the period 1962 to 1977. The dataset includes survival time in days, patient information including status, age, and sex, and tumor information including thickness.  

**Question 1: Preparing Your Workspace**

*Context:*  
This assignment will use data and functions found in the `dplyr` and `ggplot2` packages, which can be loaded using the `library()` function. 

*Instructions:*  
- Load the required packages.  
- Access the data contained in the file `mydata.csv` and store it in an object called `mydata`.  
- Print the first six rows of the data frame.  
- Generate a summary of each column using `summary()` and store it in an object called `mysummary`.  
- Look at the structure of the data frame using `str()` or `glimpse()`.    

*Assignment Code:*  
```{r}

#Set working directory
#getwd()
setwd( "C:/Users/suarep/Documents/pds/dataScience/gitRepo/lab5/r_lab5")

# Load packages
library(dplyr)
library(ggplot2)


# Access data
#Access the data contained in the file `mydata.csv` and store it in an object called `mydata`. 
mydata <- read.csv("mydata.csv")

# Print the first six rows
head(mydata)

# Generate summary statistics
#Generate a summary of each column using `summary()` and store it in an object called `mysummary`. 
mysummary <-summary(mydata)

# Look at the structure of the object
glimpse(mysummary)
str(mysummary)


```

*Feedback:*  
You will be using this dataset to explore concepts about probability and statistics.  

**Question 2: Generating Density Plots**  

*Context:*  
The Normal Distribution has some great properties for our analysis, it's a fantastic tool in our tool belt as data scientists. It can be specified by just two variables; the mean and standard deviation. However, it is important to be able to assess whether values in the data set follow the Normal Distribution or not. Density plots created using `geom_density()` are a good way to carefully look at the data. This function is very similar to `geom_histogram()`, and requires only an x variable. Here, you will also be introduced to using the argument `alpha` to control the transparency of the density plot, and `fill` to control the fill colour.  

*Instructions:*  
- Use `set.seed(123)` to ensure reproducibility.  
- Using `mutate()`, add a new column to `mydata` called `normal_thickness` and populate (fill in) this column with values taken from a normal distribution that has the same mean and standard deviation found in the `thickness` column of `mydata`. Use `?rnorm` if you need a quick reminder of how the function works.  
- Generate a densty plot of `age` using `geom_density()`. Specify that the `fill` colour should be `"blue"` and the `alpha` should be `0.2`, making it slightly transparent. Store this ggplot in an object called `plot1`.  
- Generate a densty plot of `thickness` using `geom_density()`. Specify that the `fill` colour should be `"red"` and the `alpha` should be `0.2`, making it slightly transparent. Store this ggplot in an object called `plot2`.  
- Add a `geom_density()` layer to `plot2` that displays the distribution of `normal_thickness`.  Specify that the `fill` colour should be `"green"` and the `alpha` should be `0.2`, making it slightly transparent. Store this plot in an object called `plot3`. Think about how this compares to the actual distribution of `thickness` and what it tells you about the data.  

*Assignment Code:*  
```{r}

# Set seed
#Use `set.seed(123)` to ensure reproducibility. 
set.seed(123)

# Add normal_thickness column to mydata
#Using `mutate()`, add a new column to `mydata` called `normal_thickness` and populate (fill in) this column with values taken from a normal distribution that has the same mean and standard deviation found in the `thickness` column of `mydata`. Use `?rnorm` if you need a quick reminder of how the function works.

?rnorm
?mutate

m <- mean(mydata$thickness)
m

s <- sd(mydata$thickness)
s

n <- nrow(mydata)
n

r <- rnorm(n, mean = m, sd = s)

#option1
#r <- rnorm(n, mean = mean(mydata$thickness), sd (mydata$thickness))

#option2
#mutate(mydata, normal_thickness = rnorm(n, mean = mean(mydata$thickness), sd (mydata$thickness)))

#option3
#mutate(mydata, normal_thickness = rnorm(n, mean = mean(thickness), sd(thickness)))

#overwrite and add column to data set
mydata <- mutate(mydata, normal_thickness = r)

head(mydata)

# Generate density plot of age
#Generate a densty plot of `age` using `geom_density()`. Specify that the `fill` colour should be `"blue"` and the `alpha` should be `0.2`, making it slightly transparent. Store this ggplot in an object called 'plot1`.

plot1 <- ggplot(mydata) +
  geom_density(aes(x = age), alpha = 0.2, fill = "blue")

# Look at plot1
plot1

# Generate density plot of thickness
#Generate a densty plot of `thickness` using `geom_density()`. Specify that the `fill` colour should be `"red"` and the `alpha` should be `0.2`, making it slightly transparent. Store this ggplot in an object called `plot2`. 

plot2 <- ggplot(mydata) +
  geom_density(aes(x = thickness), alpha = 0.2, fill = "red")

# Look at plot2
plot2


# Overlay density plot of normal_thickness
#Add a `geom_density()` layer to `plot2` that displays the distribution of `normal_thickness`.  Specify that the `fill` colour should be `"green"` and the `alpha` should be `0.2`, making it slightly transparent. Store this plot in an object called `plot3`. Think about how this compares to the actual distribution of `thickness` and what it tells you about the data.


plot3 <- plot2 +
  geom_density(aes(x = normal_thickness), alpha = 0.2, fill = "green")

# Look at plot3
plot3

```
*Feedback:*  
You can see from the density plots that while `age` is fairly close to being normally distributed, `thickness` is not. This is even clearer when a normal distribution is overlayed on the density plot of `thickness`! Understanding the distribution of the variables is an important consideration when deciding what analytical approaches should be used. It should be noted that in some instances, using the natural logarithm of a variable may result in a more normally distributed variable and is a useful technique. You can calculate the natural logarithm of `thickness` using `log()` to demonstrate this concept.  

**Question 3: Visualizing the Cumulative Distribution Function** 

*Context:*  
The Cumulative Distribution Function (CDF) is an important technique in many contexts, such as allocating reserves for a pension scheme. In that instance, the CDF of survival rates of policy holders would be valuable information. Here, you will look at the CDF of the thickness of melanoma cells using a specialized function from `ggplot2`, the `stat_ecdf()` function. This function can be added to `ggplot()` instead of a typical `geom_` function. Just like a `geom_` function, `stat_ecdf()` requires an `aes()` function as its first argument, and it is here the x axis variable is specified using the appropriate column name.  

*Instructions:* 
- Plot the CDF of the `thickness` of melanoma cells as a `ggplot()` using the `stat_ecdf()` layer. Store this plot in an object called `plot4`.    
- Looking at this plot, approximately what proportion (*to the nearest 0.25*) of melanoma cells are less than 4 mm thick? Store this value in an object called `estimated_proportion`.

*Assignment Code:*  

```{r}
# CDF of melanoma thickness
#Plot the CDF of the `thickness` of melanoma cells as a `ggplot()` using the `stat_ecdf()` layer. Store this plot in an object called `plot4`.


plot4 <- ggplot(mydata, aes(thickness)) + stat_ecdf()

# Look at plot4
plot4

# Estimate proportion < 4 mm to the nearest 0.25
#Looking at this plot, approximately what proportion (*to the nearest 0.25*) of melanoma cells are less than 4 mm thick? Store this value in an object called `estimated_proportion`.

estimated_proportion <- .75

```

*Feedback:*  
The shape of this curve indicates that the `thickness` variable is not normally distributed; you can see that approximately 95 % of points fall below the midpoint of `thickness` (approximately 9 mm).  

**Question 4: Calculating Overall Statistics**  

*Context:*  
You are interested in learning about the proportion of patients that fall into each level of `status`. Later you will sample the population and compare the values generated by that sample to the values found here using the full data set.  

*Instructions:*  
- Use `levels()` to examine the unique values found in the `status` column of `mydata`. Recall that `levels()` requires a factor vector as its only argument.  
- Use `dplyr` to generate a summary table that contains the proportion of records in `mydata` containing each value of `status`. This table should have two columns: `status` and `proportion`, and be stored in an object called `overall_values`.  
Hint: The proportion will be equal to the number of occurances of each level of `status` divided by the total number of rows in `mydata`. Consider how you might use `group_by()`, `summarise()`, `n()`, and `nrow()` to accomplish this task.  

```{r}
# Levels of status
#Use `levels()` to examine the unique values found in the `status` column of `mydata`. Recall that `levels()` requires a factor vector as its only argument.

levels(mydata$status)

# Generate overall_values
#Use `dplyr` to generate a summary table that contains the proportion of records in `mydata` containing each value of `status`. This table should have two columns: `status` and `proportion`, and be stored in an object called `overall_values`.  
#Hint: The proportion will be equal to the number of occurances of each level of `status` divided by the total number of rows in `mydata`. Consider how you might use `group_by()`, `summarise()`, `n()`, and `nrow()` to accomplish this task. 

levels(mydata$status)
str(mydata)
nlevels(mydata$status)

overall_values <- mydata %>%   group_by(status) %>%   summarise(proportion = n() / nrow(mydata)) 

# Look at overall_values
overall_values

```

**Question 5: Simple Random Sampling**  

*Context:*  
Sampling a population is a common analytical task. The easiest way to do this is using simple random sampling. Values calculated using the full dataset should be comparable to those calculated using a random sample of the dataset. Here, you will calculate the proportion of the data that falls into each level of `status`.  

*Instructions:*  
- Use `set.seed(123)` to ensure reproducibility.  
- Subset a simple random sample of 30 patients using `sample_n()`. Store this subset in an object called `mysimple`.  
- Generate a summary table that contains the proportion of records in `mysimple` with each level of `status`. It should have two columns: `status` and `proportion`. Store this data frame in an object called `simple_values`.  

*Assignment Code:*  
```{r}
# Set seed
#Use `set.seed(123)` to ensure reproducibility. 
set.seed(123)

# Random sample of 30 patients
-#Subset a simple random sample of 30 patients using `sample_n()`. Store this subset in an object called `mysimple`. 
  
mysimple <- sample_n(mydata, 30)
mysimple

# Find the proportion of patients at each status using the random sample
#Generate a summary table that contains the proportion of records in `mysimple` with each level of `status`. It should have two columns: `status` and `proportion`. Store this data frame in an object called `simple_values`.

simple_values <- mysimple %>%   group_by(status) %>%   summarise(proportion = n()/nrow(mysimple)) 
 
# Look at simple_values
simple_values

```

*Feedback:*  
Taking a small random sample from a large population will result in slightly different estimates. Simple random sampling is the most straightforward method, but there are instances where you will want to sample the data to produce a subset that is more reflective of the larger population.  

**Question 6: Stratified Random Sampling**  

*Context:*  
Stratified random sampling occurs when a variable in the data is used to direct how the population is sampled. This variable typically relates to some structural characteristic of the population that you want to be reflected in the subset used for analysis. For example, 62 % of the patients in the `mydata` data set are male. Therefore, a simple random sample of the data would likely contain more male patients than female. If you wanted to ensure that the subset contains an equal number of males and females, you would use stratified random sampling.  

*Instructions:*  
- Use `set.seed(123)` to ensure reproducibility.  
- Subset a random sample of 30 patients using `sample_n()`. Ensure that this subset includes an equal number of males and females by including `group_by`() in the `dplyr` pipeline. Store this subset in an object called `mystratified`.  
- Generate a summary table that contains the proportion of patients in each level of `status` using the subset `mystratified`. It should have two columns: `status` and `proportion`. Store this data frame in an object called `stratified_values`.  

*Please note that small sample sizes like the ones demonstrated here are not reliable for inference! Here, we are only illustrating the process of how to generate a random stratified sample.*  

*Assignment Code:*  
```{r}
# Set seed
#Use `set.seed(123)` to ensure reproducibility. 
set.seed(123)


# Stratified random sample of 15 records from each level of sex
#Subset a random sample of 30 patients using `sample_n()`. Ensure that this subset includes an equal number of males and females by including `group_by`() in the `dplyr` pipeline. Store this subset in an object called `mystratified`.  

mystratified <- mydata %>%
  group_by(sex) %>%
  sample_n(15)

mystratified


# Find the proportion of patients at each status using the random sample
#Generate a summary table that contains the proportion of patients in each level of `status` using the subset `mystratified`. It should have two columns: `status` and `proportion`. Store this data frame in an object called `stratified_values`. 

stratified_values <- mystratified %>%   group_by(status) %>%   summarise(proportion = n()/nrow(mystratified)) 
 

# Look at stratified_values
stratified_values

```

*Feedback:*  
Stratified random sampling is a method of extracing a subset of a population in proportion to another variable.  

**Question 7: Calculating Confidence Limits**  

*Context:*  
Typically, the confidence interval will provide you with the upper and lower ranges where our sample statistic (like a mean, or variance for example) will fall within 95 % of the time. While 95 % is the most commonly used value, it may be appropriate to be more conservative (i.e. 99 %) or less conservative (i.e. 80 %) depending on the question being asked. Here, you know that the `age` variable is approximately normally distributed, and will need to compute the 95 % confidence interval around the mean `age`.  

*Instructions:* 
- Find the mean value of `age` in `mydata`; store this in an object called `mu`.  
- Find the standard deviation of `age` in `mydata`; store this in an object called `sigma`.  
- Find the number of samples of `age` in `mydata`; store this in an object called `n`.  
- Calculate the error using `sigma`, and `n`, and the function `qnorm()`; store this in an object called `error`.  
- Find the lower confidence limit by subtracting `error` from `mu`; store this in an object called `lower`.  
- Find the upper confidence limit by adding `error` to `mu`; store this in an object called `upper`.  

*Assignment Code:*  
```{r}
# Mean age
#Find the mean value of `age` in `mydata`; store this in an object called `mu`.
mu <- mean(mydata$age)
mu

# Standard deviation of age
#Find the standard deviation of `age` in `mydata`; store this in an object called `sigma`

sigma <- sd(mydata$age)
sigma

# Number of samples
#Find the number of samples of `age` in `mydata`; store this in an object called `n`. 

n <- nrow(mydata)
n

# Calculate error
#Calculate the error using `sigma`, and `n`, and the function `qnorm()`; store this in an object called `error`. 

error <- qnorm(0.975)*sigma/sqrt(n)


# Lower confidence limit
#Find the lower confidence limit by subtracting `error` from `mu`; store this in an object called `lower`.
lower <- mu-error


# Upper confidence limit
#Find the upper confidence limit by adding `error` to `mu`; store this in an object called `upper`. 
upper <- mu+error

# Look at mu
mu

# Look at lower
lower

# Look at upper
upper

```

*Feedback:*  
Remember that the dataset is itself a random sample from a larger population. You can use this confidence interval to predict that 95 % of the time, the mean age of patients will lie between the lower and upper limits.